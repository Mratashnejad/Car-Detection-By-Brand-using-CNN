{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fff3bd4-7f8d-4f15-91d4-b2289a5b05df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Rolls royce.zip\n",
      "Data/Lamborghini.zip\n",
      "Data/Benz.zip\n",
      "Data/Kia.zip\n",
      "Data/Bmw.zip\n",
      "Data/alfa romeo.zip\n",
      "Data/Porsche.zip\n",
      "Data/Maserati.zip\n",
      "Data/Ferrari.zip\n",
      "Data/Audi.zip\n",
      "Data/Dodge.zip\n",
      "Data/Toyota.zip\n",
      "Data/Tesla.zip\n",
      "Data/Cadillac.zip\n",
      "Data/Bentley.zip\n",
      "Data/Ford mustang.zip\n",
      "Data/Ford.zip\n",
      "Data/Lexus.zip\n",
      "Data/hyundai.zip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('Data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f89c1-a52b-4937-8d25-9c8fdcac6ab4",
   "metadata": {},
   "source": [
    "I wanna make files name uniuqe but here in kaggle platform when the data are in input mode , we couldn't rename them , because all the file are read only****.\n",
    "\n",
    "to fixing this issue , we have to move data from input to output mood. and then trying to rename the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de717b4-1b6e-4616-982b-cd7dcc188cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part is For kaggle platform\n",
    "\n",
    "#import shutil\n",
    "# set the path to input and output directories\n",
    "#input_path  = '/kaggle/input/over-20-car-brands-dataset'\n",
    "#output_path = '/kaggle/working/over-20-car-brands-dataset'\n",
    "\n",
    "\n",
    "#copy the entire input directory to the output directory\n",
    "#shutil.copytree(input_path, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a24360d-77c0-4189-ac63-3493a9caa27e",
   "metadata": {},
   "source": [
    "### try to unzip files into the Data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d399a59e-733c-4050-a57d-83ce0376bd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Rolls royce.zip\n",
      "Extracted Lamborghini.zip\n",
      "Extracted Benz.zip\n",
      "Extracted Kia.zip\n",
      "Extracted Bmw.zip\n",
      "Extracted alfa romeo.zip\n",
      "Extracted Porsche.zip\n",
      "Extracted Maserati.zip\n",
      "Extracted Ferrari.zip\n",
      "Extracted Audi.zip\n",
      "Extracted Dodge.zip\n",
      "Extracted Toyota.zip\n",
      "Extracted Tesla.zip\n",
      "Extracted Cadillac.zip\n",
      "Extracted Bentley.zip\n",
      "Extracted Ford mustang.zip\n",
      "Extracted Ford.zip\n",
      "Extracted Lexus.zip\n",
      "Extracted hyundai.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "#set path for directories \n",
    "zip_dir = 'Data'\n",
    "\n",
    "#get list of all zip files in directories \n",
    "zip_files = [f for f in os.listdir(zip_dir) if f.endswith('.zip')]\n",
    "\n",
    "#looping on the all directory\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    #set path to zip file\n",
    "    zip_path     = os.path.join(zip_dir , zip_file)\n",
    "    \n",
    "    #set path in directory where we wanna to extract file\n",
    "    extract_path = os.path.join(zip_dir , os.path.splitext(zip_file)[0])\n",
    "    \n",
    "    #create directory if it dosen't exist\n",
    "    os.makedirs(extract_path , exist_ok=True)\n",
    "    \n",
    "    #Extract zip files into the directory\n",
    "    with zipfile.ZipFile(zip_path , 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "        #print the extraced files.\n",
    "        print(f\"Extracted {zip_file}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9c3ab-07c9-44eb-ac4b-f01c9f0603e5",
   "metadata": {},
   "source": [
    "### First renaming images to unique names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "854acdde-36de-4486-a853-7b7462319d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "#set path \n",
    "dataset_path = 'Data'\n",
    "\n",
    "#intrate over the subdirectoreis in dataset directory\n",
    "for sub_dir in os.listdir(dataset_path):\n",
    "    sub_dir_path = os.path.join(dataset_path , sub_dir)\n",
    "    if os.path.isdir(sub_dir_path):\n",
    "        #get the list of image files in the subdirectory\n",
    "        image_files = [f for f in os.listdir(sub_dir_path) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.svg')]\n",
    "        \n",
    "        #rename each image file with a unique name\n",
    "        for i, file_name in enumerate(image_files):\n",
    "            src_path = os.path.join(sub_dir_path, file_name)\n",
    "            file_ext = os.path.splitext(file_name)[1]\n",
    "            dst_name = str(uuid.uuid4()) + file_ext\n",
    "            dst_path = os.path.join(sub_dir_path,dst_name)\n",
    "            os.rename(src_path , dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afe7984-8b2e-418a-b658-512d359f00f0",
   "metadata": {},
   "source": [
    "### Now Data are Renamed by unique names inside their folders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8bc5f-c2e6-4239-8464-f422de499bd4",
   "metadata": {},
   "source": [
    "Well , Now our files are renamed and ready to next step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35db47-5230-44df-ac55-12bdca8bc60d",
   "metadata": {},
   "source": [
    "### Spliting files to Training and testing Folders automaticly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632d773-be0c-410f-b7b1-449706cf016f",
   "metadata": {},
   "source": [
    "i do it beacuse the amont of data are too much, and i wanna split **80% of data to traning** and **20% to testing** folders inside each folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4aee7680-e330-4973-a116-81010ff0c4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "dataset_path = 'Data'\n",
    "train_path = 'Data/train'\n",
    "test_path = 'Data/test'\n",
    "clear_data_path = 'Data/ClearData'\n",
    "zip_data_path = 'Data/ZipData'\n",
    "\n",
    "# check if directories exist\n",
    "os.makedirs(clear_data_path, exist_ok=True)\n",
    "os.makedirs(zip_data_path, exist_ok=True)\n",
    "\n",
    "\n",
    "split_ratio = 0.8\n",
    "\n",
    "for sub_dir in os.listdir(dataset_path):\n",
    "    if sub_dir.startswith('.'):\n",
    "        continue  # skip hidden files\n",
    "    sub_dir_path = os.path.join(dataset_path, sub_dir)\n",
    "\n",
    "\n",
    "    train_sub_dir_path = os.path.join(train_path, sub_dir)\n",
    "    test_sub_dir_path = os.path.join(test_path, sub_dir)\n",
    "\n",
    "    os.makedirs(train_sub_dir_path, exist_ok=True)\n",
    "    os.makedirs(test_sub_dir_path, exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(sub_dir_path) if f.endswith('.jpg') or f.endswith('.jpeg')\n",
    "                   or f.endswith('.png') or f.endswith('.svg')]\n",
    "\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    split_index = int(len(image_files) * split_ratio)\n",
    "\n",
    "    train_files = image_files[:split_index]\n",
    "    test_files = image_files[split_index:]\n",
    "\n",
    "    for file_name in train_files:\n",
    "        src_path = os.path.join(sub_dir_path, file_name)\n",
    "        dst_path = os.path.join(train_sub_dir_path, file_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "    for file_name in test_files:\n",
    "        src_path = os.path.join(sub_dir_path, file_name)\n",
    "        dst_path = os.path.join(test_sub_dir_path, file_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(\"Dataset split into training and testing sets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dec3cf-6d22-4e3b-a473-669c3cb9251c",
   "metadata": {},
   "source": [
    "Now our folders are not Clear and sort whitin this part of code i tring to moving data to Data folder ,  and have Train and Test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f114b2-c6b2-4cf6-963f-c6acc7291557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
